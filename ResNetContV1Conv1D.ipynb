{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# from https://github.com/hauser-group/odft_tools\n",
    "from odft_tools.layers import (\n",
    "    IntegrateLayer,\n",
    "    Continuous1DConvV1\n",
    ")\n",
    "\n",
    "from odft_tools.models_resnet_ccn import (\n",
    "    ResNetContConv1DModel,\n",
    "    ResNetContConv1DV2Model,\n",
    "    ResNetConv1DModel\n",
    ")\n",
    "\n",
    "from odft_tools.utils import (\n",
    "    plot_derivative_energy,\n",
    "    plot_gaussian_weights_v1\n",
    ")\n",
    "\n",
    "from odft_tools.keras_utils import (\n",
    "    WarmupExponentialDecay\n",
    ")\n",
    "\n",
    "from tensorflow.python.framework import dtypes\n",
    "import random\n",
    "\n",
    "data_path = '../datasets/orbital_free_DFT/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['energies', 'potential', 'wavefunctions']>\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(data_path + 'dataset_large.hdf5', 'r') as f:\n",
    "    keys = f.keys()\n",
    "    print(keys)\n",
    "    # build a dict (dataset.value has been deprecated. Use dataset[()] instead.)\n",
    "    data = {key:f[key][()] for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 500)\n",
    "dx = x[1] - x[0]\n",
    "N = 1\n",
    "# density is wavefunction squared\n",
    "n = np.sum(data['wavefunctions'][:, :, :N]**2, axis=-1)\n",
    "# integrate using trapezoidal rule:\n",
    "V = np.sum(0.5*(data['potential'][:, :-1]*n[:, :-1] \n",
    "                + data['potential'][:, 1:]*n[:, 1:])           \n",
    "           * dx, axis=-1)\n",
    "# kinetic energy is total energy minus potential energy\n",
    "T = np.sum(data['energies'][:, :N], axis=-1) - V\n",
    "# kinetic energy derivative\n",
    "dT_dn = np.expand_dims(np.sum(data['energies'][:, :N], axis=-1)/N, axis=-1) - data['potential']\n",
    "n = n.reshape((-1, 500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['energies', 'potential', 'wavefunctions']>\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(data_path + 'dataset_validate.hdf5', 'r') as f:\n",
    "    keys = f.keys()\n",
    "    print(keys)\n",
    "    # build a dict (dataset.value has been deprecated. Use dataset[()] instead.)\n",
    "    data_test = {key:f[key][()] for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# density is wavefunction squared\n",
    "n_test = np.sum(data_test['wavefunctions'][:, :, :N]**2, axis=-1)\n",
    "# integrate using trapezoidal rule:\n",
    "V_test = np.sum(0.5*(data_test['potential'][:, :-1]*n_test[:, :-1] \n",
    "                + data_test['potential'][:, 1:]*n_test[:, 1:])           \n",
    "                * dx, axis=-1)\n",
    "# kinetic energy is total energy minus potential energy\n",
    "T_test = np.sum(data_test['energies'][:, :N], axis=-1) - V_test\n",
    "# kinetic energy derivative\n",
    "dT_dn_test = - data_test['potential'] + np.expand_dims(np.sum(data_test['energies'][:, :N], axis=-1)/N, axis=-1) \n",
    "n_test = n_test.reshape((-1, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------->Start<---------------------------------\n",
      "No Cont Layer. res_net 4 with 50\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "density (InputLayer)            [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 500, 1)       0           density[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "continuous1d_conv_v1 (Continuou (None, 500, 32)      3232        lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Conv1D_noact_0 (Conv1D)         (None, 500, 32)      102432      continuous1d_conv_v1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 500, 32)      0           Conv1D_noact_0[0][0]             \n",
      "                                                                 lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "act0 (Activation)               (None, 500, 32)      0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "Conv1D_act_1 (Conv1D)           (None, 500, 32)      102432      act0[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Conv1D_noact_1 (Conv1D)         (None, 500, 32)      102432      Conv1D_act_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 500, 32)      0           Conv1D_noact_1[0][0]             \n",
      "                                                                 act0[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "act1 (Activation)               (None, 500, 32)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1D_act_2 (Conv1D)           (None, 500, 32)      102432      act1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Conv1D_noact_2 (Conv1D)         (None, 500, 32)      102432      Conv1D_act_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 500, 32)      0           Conv1D_noact_2[0][0]             \n",
      "                                                                 act1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "act2 (Activation)               (None, 500, 32)      0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1D_act_3 (Conv1D)           (None, 500, 32)      102432      act2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Conv1D_noact_3 (Conv1D)         (None, 500, 32)      102432      Conv1D_act_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 500, 32)      0           Conv1D_noact_3[0][0]             \n",
      "                                                                 act2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "act3 (Activation)               (None, 500, 32)      0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1D_end_3 (Conv1D)           (None, 500, 1)       3201        act3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dT_dn (Lambda)                  (None, 500)          0           Conv1D_end_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "integrate_layer (IntegrateLayer (None,)              0           dT_dn[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 723,457\n",
      "Trainable params: 723,457\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "32/32 - 59s - loss: 12.8432 - T_loss: 2.4716 - dT_dn_loss: 12.3489 - T_mae: 1.1829 - dT_dn_mae: 2.6772\n",
      "Epoch 2/50\n",
      "32/32 - 62s - loss: 4.8046 - T_loss: 0.2285 - dT_dn_loss: 4.7589 - T_mae: 0.4033 - dT_dn_mae: 1.6979\n",
      "Epoch 3/50\n",
      "32/32 - 66s - loss: 2.9724 - T_loss: 0.0673 - dT_dn_loss: 2.9589 - T_mae: 0.2007 - dT_dn_mae: 1.3638\n",
      "Epoch 4/50\n",
      "32/32 - 74s - loss: 2.6742 - T_loss: 0.0441 - dT_dn_loss: 2.6654 - T_mae: 0.1631 - dT_dn_mae: 1.2862\n",
      "Epoch 5/50\n",
      "32/32 - 64s - loss: 2.4848 - T_loss: 0.0610 - dT_dn_loss: 2.4726 - T_mae: 0.2088 - dT_dn_mae: 1.2311\n",
      "Epoch 6/50\n",
      "32/32 - 73s - loss: 2.2408 - T_loss: 0.0191 - dT_dn_loss: 2.2370 - T_mae: 0.1142 - dT_dn_mae: 1.1511\n",
      "Epoch 7/50\n",
      "32/32 - 76s - loss: 2.0958 - T_loss: 0.0392 - dT_dn_loss: 2.0880 - T_mae: 0.1452 - dT_dn_mae: 1.0938\n",
      "Epoch 8/50\n",
      "32/32 - 63s - loss: 2.0080 - T_loss: 0.0512 - dT_dn_loss: 1.9977 - T_mae: 0.1859 - dT_dn_mae: 1.0622\n",
      "Epoch 9/50\n",
      "32/32 - 66s - loss: 1.9558 - T_loss: 0.0432 - dT_dn_loss: 1.9472 - T_mae: 0.1677 - dT_dn_mae: 1.0479\n",
      "Epoch 10/50\n",
      "32/32 - 92s - loss: 1.8433 - T_loss: 0.0268 - dT_dn_loss: 1.8380 - T_mae: 0.1336 - dT_dn_mae: 1.0049 - val_loss: 1.7331 - val_T_loss: 0.0695 - val_dT_dn_loss: 1.7192 - val_T_mae: 0.2626 - val_dT_dn_mae: 0.9687\n",
      "Epoch 11/50\n",
      "32/32 - 62s - loss: 1.7863 - T_loss: 0.0443 - dT_dn_loss: 1.7775 - T_mae: 0.1671 - dT_dn_mae: 0.9877\n",
      "Epoch 12/50\n",
      "32/32 - 59s - loss: 1.7530 - T_loss: 0.0615 - dT_dn_loss: 1.7407 - T_mae: 0.2109 - dT_dn_mae: 0.9806\n",
      "Epoch 13/50\n",
      "32/32 - 58s - loss: 1.6761 - T_loss: 0.0351 - dT_dn_loss: 1.6691 - T_mae: 0.1533 - dT_dn_mae: 0.9580\n",
      "Epoch 14/50\n",
      "32/32 - 59s - loss: 1.6212 - T_loss: 0.0357 - dT_dn_loss: 1.6141 - T_mae: 0.1585 - dT_dn_mae: 0.9395\n",
      "Epoch 15/50\n",
      "32/32 - 64s - loss: 1.5539 - T_loss: 0.0306 - dT_dn_loss: 1.5478 - T_mae: 0.1389 - dT_dn_mae: 0.9197\n",
      "Epoch 16/50\n",
      "32/32 - 73s - loss: 1.5287 - T_loss: 0.1316 - dT_dn_loss: 1.5024 - T_mae: 0.2943 - dT_dn_mae: 0.9123\n",
      "Epoch 17/50\n",
      "32/32 - 72s - loss: 1.4618 - T_loss: 0.0709 - dT_dn_loss: 1.4476 - T_mae: 0.2206 - dT_dn_mae: 0.8949\n",
      "Epoch 18/50\n",
      "32/32 - 62s - loss: 1.3721 - T_loss: 0.1175 - dT_dn_loss: 1.3486 - T_mae: 0.2830 - dT_dn_mae: 0.8574\n",
      "Epoch 19/50\n",
      "32/32 - 67s - loss: 1.2168 - T_loss: 0.0364 - dT_dn_loss: 1.2095 - T_mae: 0.1564 - dT_dn_mae: 0.7972\n",
      "Epoch 20/50\n",
      "32/32 - 98s - loss: 1.1343 - T_loss: 0.0211 - dT_dn_loss: 1.1301 - T_mae: 0.1199 - dT_dn_mae: 0.7728 - val_loss: 1.1001 - val_T_loss: 0.0037 - val_dT_dn_loss: 1.0994 - val_T_mae: 0.0565 - val_dT_dn_mae: 0.7564\n",
      "Epoch 21/50\n",
      "32/32 - 77s - loss: 1.0210 - T_loss: 0.0396 - dT_dn_loss: 1.0131 - T_mae: 0.1630 - dT_dn_mae: 0.7252\n",
      "Epoch 22/50\n",
      "32/32 - 61s - loss: 0.9108 - T_loss: 0.0721 - dT_dn_loss: 0.8964 - T_mae: 0.2193 - dT_dn_mae: 0.6783\n",
      "Epoch 23/50\n",
      "32/32 - 61s - loss: 0.8894 - T_loss: 0.1187 - dT_dn_loss: 0.8657 - T_mae: 0.2918 - dT_dn_mae: 0.6792\n",
      "Epoch 24/50\n",
      "32/32 - 67s - loss: 0.7704 - T_loss: 0.0438 - dT_dn_loss: 0.7617 - T_mae: 0.1732 - dT_dn_mae: 0.6247\n",
      "Epoch 25/50\n",
      "32/32 - 68s - loss: 0.7143 - T_loss: 0.0384 - dT_dn_loss: 0.7066 - T_mae: 0.1543 - dT_dn_mae: 0.6025\n",
      "Epoch 26/50\n"
     ]
    }
   ],
   "source": [
    "kernel_size = 100\n",
    "mean = 5\n",
    "stddev = 5\n",
    "\n",
    "num_res_net_blocks = 4\n",
    "epoch = 50\n",
    "\n",
    "density = {'n': n.astype(np.float32)}\n",
    "targetdata = {'T': T.astype(np.float32), 'dT_dn': dT_dn.astype(np.float32)}\n",
    "\n",
    "# training_dataset = tf.data.Dataset.from_tensor_slices((n.astype(np.float32), {'T': T.astype(np.float32), 'dT_dn': dT_dn.astype(np.float32)})).batch(100).repeat(10)\n",
    "\n",
    "initial_learning_rate = 0.0001\n",
    "decay_steps = 2000\n",
    "decay_rate= 0.9\n",
    "\n",
    "initial_learning_rate = WarmupExponentialDecay(\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    decay_steps=decay_steps,\n",
    "    decay_rate=decay_rate,\n",
    "    staircase=False,\n",
    "    name=None\n",
    ")\n",
    "\n",
    "path = '/ResNetConv1D/'\n",
    "\n",
    "\n",
    "seed = 0\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "model = ResNetContConv1DModel(\n",
    "    filter_size=32,\n",
    "    kernel_size=100,\n",
    "    layer_size=None,\n",
    "    num_res_net_blocks=num_res_net_blocks,\n",
    "    weights_gaus=[5, 5],l == 0\n",
    "    n_outputs=None,\n",
    "    random_init=True,\n",
    "    dx=0.002\n",
    ")\n",
    "\n",
    "model.create_res_net_model()\n",
    "model.build(input_shape=(1, 500))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=initial_learning_rate, amsgrad=False), \n",
    "              loss={'T': 'mse', 'dT_dn': 'mse'}, \n",
    "              loss_weights={'T': 0.2, 'dT_dn': 1.0}, # As recommended by Manuel: scale the loss in T by 0.2\n",
    "              metrics={'T': ['mae'], 'dT_dn': ['mae']})\n",
    "print('--------------------------------->Start<---------------------------------')\n",
    "print(f'No Cont Layer. res_net {num_res_net_blocks} with {epoch}')\n",
    "\n",
    "model.models.summary()\n",
    "weights_before_train = model.layers[0].get_weights()[0]\n",
    "model.fit(x=density, y=targetdata, epochs=epoch, verbose=2, validation_data=(n_test, {'T': T_test, 'dT_dn': dT_dn_test}), validation_freq=10)\n",
    "weights_after_train = model.layers[0].get_weights()[0]\n",
    "print('--------------------------------->END<---------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gaussian_weights_v1(weights_before_train, ' before', path)\n",
    "plot_gaussian_weights_v1(weights_after_train, ' after', path)\n",
    "plot_derivative_energy(x, dT_dn, model, n, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([])\n",
    "df['loss'] = model.history.history['loss']\n",
    "df['dT_dn_loss'] = model.history.history['dT_dn_loss']\n",
    "df['T_loss'] = model.history.history['T_loss']\n",
    "\n",
    "df.to_csv('results' + path + '/losses.csv')\n",
    "\n",
    "plt.figure(figsize=(20, 3))\n",
    "\n",
    "plt.plot(df['loss'][1:])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss a.u.')\n",
    "plt.title('loss over epochs for ResNet CCNN')\n",
    "plt.savefig('loss_ResNet_CNNV1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_derivative_energy(x, dT_dn, model, n, result_type, ind_from, ind_to, side):\n",
    "    if not os.path.exists('results' + result_type):\n",
    "        os.makedirs('results' + result_type)\n",
    "    x = x[ind_from:ind_to]\n",
    "    plt.plot(x, dT_dn[0][ind_from:ind_to])\n",
    "    plt.plot(x, tf.squeeze(model(n[0].reshape((1, 500, 1)).astype(np.float32))['dT_dn'])[ind_from:ind_to])\n",
    "    plt.ylabel('dT_dn')\n",
    "    plt.title('Comparison reference with trained energy derivative')\n",
    "    plt.show()\n",
    "\n",
    "# plot_derivative_energy(x, dT_dn, model, n, result_type, 0, 80, 'left')\n",
    "# plot_derivative_energy(x, dT_dn, model, n, result_type, 420, 500, 'right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
