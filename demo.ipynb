{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from https://github.com/hauser-group/odft_tools\n",
    "from odft_tools.layers import (\n",
    "    IntegrateLayer,\n",
    "    Continuous1DConvV1,\n",
    "    Continuous1DConvV2\n",
    ")\n",
    "\n",
    "data_path = '../datasets/orbital_free_DFT/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "Both data .hdf5-Files can be downloaded from https://github.com/hauser-group/datasets/tree/master/orbital_free_DFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(data_path + 'M=100_training_data.hdf5', 'r') as f:\n",
    "    keys = f.keys()\n",
    "    print(keys)\n",
    "    # build a dict (dataset.value has been deprecated. Use dataset[()] instead.)\n",
    "    data = {key:f[key][()] for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 500)\n",
    "dx = x[1] - x[0]\n",
    "N = 1\n",
    "# density is wavefunction squared\n",
    "n = np.sum(data['wavefunctions'][:, :, :N]**2, axis=-1)\n",
    "# integrate using trapezoidal rule:\n",
    "V = np.sum(0.5*(data['potential'][:, :-1]*n[:, :-1] \n",
    "                + data['potential'][:, 1:]*n[:, 1:])           \n",
    "           * dx, axis=-1)\n",
    "# kinetic energy is total energy minus potential energy\n",
    "T = np.sum(data['energies'][:, :N], axis=-1) - V\n",
    "# kinetic energy derivative\n",
    "dT_dn = np.expand_dims(np.sum(data['energies'][:, :N], axis=-1)/N, axis=-1) - data['potential']\n",
    "n = n.reshape((-1, 500, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(data_path + 'test_data.hdf5', 'r') as f:\n",
    "    keys = f.keys()\n",
    "    print(keys)\n",
    "    # build a dict (dataset.value has been deprecated. Use dataset[()] instead.)\n",
    "    data_test = {key:f[key][()] for key in keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# density is wavefunction squared\n",
    "n_test = np.sum(data_test['wavefunctions'][:, :, :N]**2, axis=-1)\n",
    "# integrate using trapezoidal rule:\n",
    "V_test = np.sum(0.5*(data_test['potential'][:, :-1]*n_test[:, :-1] \n",
    "                + data_test['potential'][:, 1:]*n_test[:, 1:])           \n",
    "                * dx, axis=-1)\n",
    "# kinetic energy is total energy minus potential energy\n",
    "T_test = np.sum(data_test['energies'][:, :N], axis=-1) - V_test\n",
    "# kinetic energy derivative\n",
    "dT_dn_test = - data_test['potential'] + np.expand_dims(np.sum(data_test['energies'][:, :N], axis=-1)/N, axis=-1) \n",
    "n_test = n_test.reshape((-1, 500, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, layers=[32,], kernel_size=64, dx=1.0):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dx = dx\n",
    "        self.conv_layers = []\n",
    "        for l in layers:\n",
    "            self.conv_layers.append(tf.keras.layers.Conv1D(l, kernel_size, padding='same', activation='exponential'))\n",
    "        # last layer is fixed to use a single filter\n",
    "        self.conv_layers.append(tf.keras.layers.Conv1D(1, kernel_size, padding='same', activation='linear'))\n",
    "        self.integrate = IntegrateLayer(dx)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(inputs)\n",
    "            # Calculate kinetic energy density tau by applying convolutional layers\n",
    "            tau = inputs\n",
    "            for layer in self.conv_layers:\n",
    "                tau = layer(tau)\n",
    "            # Kinetic energy T is integral over kinetiv energy density\n",
    "            T = self.integrate(tau)\n",
    "        # The discretized derivative needs to be divided by dx\n",
    "        dT_dn = tape.gradient(T, inputs)/self.dx\n",
    "        return {'T': T, 'dT_dn': dT_dn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 5\n",
    "stddev = 5\n",
    "\n",
    "class MyModelCont(tf.keras.Model):\n",
    "    def __init__(self, layers=[32,], kernel_size=64, dx=1.0):\n",
    "        super(MyModelCont, self).__init__()\n",
    "        self.dx = dx\n",
    "        self.conv_layers = []\n",
    "        \n",
    "        for l in layers:\n",
    "            cont_layer = Continuous1DConvV1(\n",
    "                   filters=32,\n",
    "                   kernel_size=kernel_size,\n",
    "                   activation='softplus',\n",
    "                   padding='same',\n",
    "                   weights_init=[mean, stddev]\n",
    "               )\n",
    "            self.conv_layers.append(cont_layer)\n",
    "            # self.conv_layers.append(cont_layer)\n",
    "        # last layer is fixed to use a single filter\n",
    "        cont_layer = Continuous1DConvV1(\n",
    "            filters=1,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='linear',\n",
    "            padding='same',\n",
    "            weights_init=[mean, stddev]\n",
    "        )\n",
    "        self.conv_layers.append(cont_layer)\n",
    "        self.integrate = IntegrateLayer(dx)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(inputs)\n",
    "            # Calculate kinetic energy density tau by applying convolutional layers\n",
    "            tau = inputs\n",
    "            for layer in self.conv_layers:\n",
    "                tau = layer(tau)\n",
    "            # Kinetic energy T is integral over kinetiv energy density\n",
    "            T = self.integrate(tau)\n",
    "        # The discretized derivative needs to be divided by dx\n",
    "        dT_dn = tape.gradient(T, inputs)/self.dx\n",
    "        return {'T': T, 'dT_dn': dT_dn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 100\n",
    "# Feel free to use larger kernel size (Manuel used 100) and larger networks (Manuels ResNet used layers=[32, 32, 32, 32, 32, 32]).\n",
    "model = MyModelCont(layers=[32, ], kernel_size=kernel_size, dx=dx)\n",
    "# Tell the model what input to expect. The first dimension (None) represents the batch size and remains undefinded.\n",
    "model.build(input_shape=(None, 500, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              loss={'T': 'mse', 'dT_dn': 'mse'}, \n",
    "              loss_weights={'T': 0.2, 'dT_dn': 1.0}, # As recommended by Manuel: scale the loss in T by 0.2\n",
    "              metrics={'T': ['mae'], 'dT_dn': ['mae']})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a dataset that repeats the data (cast to float32) 10 times to reduce output in model.fit().\n",
    "# Note that this step is not necessary, you could simply feed the numpy arrays into the model.fit() method.\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices((n.astype(np.float32), {'T': T.astype(np.float32), 'dT_dn': dT_dn.astype(np.float32)})).batch(100).repeat(10)\n",
    "\n",
    "result_type = '/ContCNNV1/32_1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weigths = model.layers[0].get_weights()[0]\n",
    "\n",
    "truncate = kernel_size/2\n",
    "\n",
    "width = int(truncate + 0.5)\n",
    "# width = int(truncate * stddev + 0.5)\n",
    "support = np.arange(-width, width + 1)\n",
    "center = int(len(support)/2)\n",
    "\n",
    "left_cut = center - int(kernel_size/2)\n",
    "right_cut = center + int(kernel_size/2)\n",
    "\n",
    "for mean, stddev in zip(weigths[0][0], weigths[1][0]):\n",
    "    gauss_kernel = np.exp(-((support - mean) ** 2)/(2*stddev ** 2))\n",
    "    gauss_kernel = gauss_kernel / gauss_kernel.sum()\n",
    "\n",
    "    if (kernel_size % 2) != 0:\n",
    "        gauss_kernel = gauss_kernel[left_cut + 1:right_cut + 2]\n",
    "    else:\n",
    "        gauss_kernel = gauss_kernel[left_cut + 1:right_cut + 1]\n",
    "    plt.plot(gauss_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weigths = model.layers[0].get_weights()[0]\n",
    "plt.ylabel('density')\n",
    "plt.xlabel('kernel size')\n",
    "plt.title('Gaussian Kernel of ContConv1V1 with Layer softplus act. fun')\n",
    "plt.plot(weigths[:, 0, :])\n",
    "plt.savefig('results' + result_type + 'gauss_kernel_softplus_act_V1.png')\n",
    "plt.show()\n",
    "\n",
    "weigths = model.layers[1].get_weights()[0]\n",
    "plt.ylabel('density')\n",
    "plt.xlabel('kernel size')\n",
    "plt.title('Gaussian Kernel of ContConv1V1 with Layer linear act. fun')\n",
    "plt.plot(weigths[:, 0, :])\n",
    "plt.savefig('results' + result_type + 'gauss_kernel_linear_act_V1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weigts_old1 = weigths[:, 0, :]\n",
    "weigts_old2 = weigths[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beware when comparing the results to our paper. The output here is in Hartree!\n",
    "model.fit(training_dataset, epochs=200, verbose=2, validation_data=(n_test, {'T': T_test, 'dT_dn': dT_dn_test}), validation_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect results\n",
    "The prediction by the CNN exhibits rapid oscillations, which we hope to eliminate by going from a convolution with a discrete kernel towards a convolution with a continuous function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, dT_dn[0])\n",
    "plt.plot(x, tf.squeeze(model(n[0].reshape((1, 500, 1)).astype(np.float32))['dT_dn']))\n",
    "plt.ylabel('dT_dn')\n",
    "plt.title('Comparison reference with trained')\n",
    "plt.savefig('results' + result_type + 'dT_dn_V1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weigths = model.layers[0].get_weights()[0]\n",
    "plt.ylabel('density')\n",
    "plt.xlabel('kernel size')\n",
    "plt.title('Gaussian Kernel of ContConv1V1 with Layer softplus act. fun after')\n",
    "plt.plot(weigths[:, 0, :])\n",
    "plt.savefig('results' + result_type + 'gauss_kernel_softplus_act_V1_after.png')\n",
    "plt.show()\n",
    "\n",
    "weigths = model.layers[1].get_weights()[0]\n",
    "plt.ylabel('density')\n",
    "plt.xlabel('kernel size')\n",
    "plt.title('Gaussian Kernel of ContConv1V1 with Layer linear act. fun after')\n",
    "plt.plot(weigths[:, 0, :])\n",
    "plt.savefig('results' + result_type + 'gauss_kernel_linear_act_V1_after.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weigths = model.layers[0].get_weights()[0]\n",
    "\n",
    "truncate = kernel_size/2\n",
    "\n",
    "width = int(truncate + 0.5)\n",
    "# width = int(truncate * stddev + 0.5)\n",
    "support = np.arange(-width, width + 1)\n",
    "center = int(len(support)/2)\n",
    "\n",
    "left_cut = center - int(kernel_size/2)\n",
    "right_cut = center + int(kernel_size/2)\n",
    "\n",
    "for mean, stddev in zip(weigths[0][0], weigths[1][0]):\n",
    "    gauss_kernel = np.exp(-((support - mean) ** 2)/(2*stddev ** 2))\n",
    "    gauss_kernel = gauss_kernel / gauss_kernel.sum()\n",
    "\n",
    "    if (kernel_size % 2) != 0:\n",
    "        gauss_kernel = gauss_kernel[left_cut + 1:right_cut + 2]\n",
    "    else:\n",
    "        gauss_kernel = gauss_kernel[left_cut + 1:right_cut + 1]\n",
    "    plt.plot(gauss_kernel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
