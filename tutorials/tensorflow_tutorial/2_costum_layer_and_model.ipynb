{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3eede7-fb97-474d-bf47-3dd6d0b50849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf128fd-81d6-4e44-b141-806ef85bb311",
   "metadata": {},
   "source": [
    "A keras model will have following methods which are interesting to overwrite:\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49716561-1f7f-4d62-8476-39fca8d03dfc",
   "metadata": {},
   "source": [
    "Example: We want to make a custom CNN model.\n",
    "\n",
    "We are going to use the classic cifar10 dataset and build a CNN that classifies the images to a label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3b4684-f2c4-4380-a567-783e1ca0bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134c7f21-5832-4579-a77c-7f42aa57cce2",
   "metadata": {},
   "source": [
    "Let's take a look on the data. Always a good idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f8e998-d1c0-4d1b-afb0-7834a3f54c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5 ,5, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])    \n",
    "    plt.imshow(train_images[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87517d1-6c0e-4d54-b5c2-829089944714",
   "metadata": {},
   "source": [
    "How does a feature \"extraction\" extraction looks like with an CNN?\n",
    "\n",
    "Here is a nice animation:\n",
    "https://www.youtube.com/watch?v=f0t-OCG79-U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ed680-08b5-4150-ab31-4c6f057a5857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are printing the shape of the training and input data\n",
    "\n",
    "# This is going to be the dimension for the input data\n",
    "shape_train_images = np.shape(train_images)\n",
    "print(f'length of train images: {shape_train_images[0]}, shape of train images: {shape_train_images[1:]}')\n",
    "\n",
    "# This is going to be the dimension for the target data\n",
    "shape_train_labels = np.shape(train_labels)\n",
    "print(f'length of train label: {shape_train_labels[0]}, shape of train label: {shape_train_labels[1]}')\n",
    "\n",
    "# This shows us the length of our data and the dimension\n",
    "# We are going to need this info for constructing our CNN\n",
    "\n",
    "# What we can read from the prints is that we have 50000 input 32x32 pixel images with 4 color values for each pixel - RGB\n",
    "# and 50000 target data with a label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8b150f-70c0-453d-9f67-61c4ea7d2b71",
   "metadata": {},
   "source": [
    "## The Custom Layer\n",
    "We are goping to inerhit from tf.keras.layers.Layer and build a 'custom' dense layer.<br>\n",
    "Basically we are building a dense like it's already inplemented in tensorflow.\n",
    "\n",
    "The best way to build a custom layer is to overwritte these methods if needed:\n",
    "- __ init __ , here you input-independent initialization\n",
    "- build, with the shape info of the input you can do the rest of the init\n",
    "- call, forward computation\n",
    "\n",
    "A dense layer is nothing other than a elementwise multiplication between the inputs and the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5859615-ed10-4f28-a40d-698cf4599ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDenseLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_outputs, activation):\n",
    "    super(CustomDenseLayer, self).__init__()\n",
    "    # here we specify how many units (weights) we are going to have in the layer\n",
    "    self._num_outputs = num_outputs\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    # Here we obviously add the weights to the kerne.\n",
    "    # For that, we need the info of the dimension/weights/units (input_shape[-1]) from the previous layer\n",
    "    # and the amopunts of the units/weights (num_outputs) of this dense layer\n",
    "    self.kernel = self.add_weight(\"kernel\",\n",
    "                                  shape=[int(input_shape[-1]),\n",
    "                                         self._num_outputs])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # And here we define the element-wise multiplication of the input with the kernel.\n",
    "    return tf.matmul(inputs, self.kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37fa02e-1bf5-454f-aa24-5440f3f3a750",
   "metadata": {},
   "source": [
    "## The Custom Model\n",
    "We are going to inerhit from keras.Model and build a 'custom' sequential model.<br>\n",
    "\n",
    "The best way to build a custom model is to overwritte these methods:\n",
    "- __ init __ , here you input-independent initialization\n",
    "- call, forward computation\n",
    "\n",
    "We could also overwrite methods like fit, build... see documentation for more (https://www.tensorflow.org/api_docs/python/tf/keras/Model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608068c3-749b-495a-a4f7-c2a9f6fd952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(keras.Model):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(CustomCNN, self).__init__()\n",
    "        # First Layer is a 3 dimensional convolutional layer, with 32 filters,\n",
    "        # where each filter has a kernel size of 3x3\n",
    "        self._conf_layer_1 = tf.keras.layers.Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(3, 3),\n",
    "            activation='relu',\n",
    "            input_shape=(32, 32, 3)\n",
    "        )\n",
    "        # With the pooling layer we are reducing the dimension (downsampling the input along its spatial dimensions)\n",
    "        # by taking the maximum value over an input window, the pool size\n",
    "        self._pooling_layer_1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self._conf_layer_2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')\n",
    "        self._pooling_layer_2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self._conv_layer_3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')\n",
    "        # With Flatten we flatten the input (always good to explain the word with the word itself)\n",
    "        # We are reducing the dimension from (64, 3, 3) to (64). Why. We want to get a propability in one dimension.\n",
    "        self._flatten = layers.Flatten()\n",
    "        self._dense = CustomDenseLayer(64, activation='relu')\n",
    "        # We reduce from 64 to 10. We get 10 numbers who describe to which ot the then classes the picture belongs.\n",
    "        # So, the probability of which of the 10 classes the image belongs to\n",
    "        self._dense_2 = CustomDenseLayer(10, activation='linear')\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        # In the call method we sequentially propagate the input to the former defined layers. \n",
    "        x = self._conf_layer_1(inputs)\n",
    "        x = self._pooling_layer_1(x)\n",
    "        x = self._conf_layer_2(x)\n",
    "        x = self._pooling_layer_2(x)\n",
    "        x = self._conv_layer_3(x)\n",
    "        x = self._flatten(x)\n",
    "        x = self._dense(x)\n",
    "        x = self._dense_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786e6ebf-d864-4b47-8580-9d8e51325844",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomCNN()\n",
    "\n",
    "# 32, 32, 3 like we saw before is our input shape. The None stands for the 'dimension' of how many input data we have\n",
    "input_shape = (None, 32, 32, 3)\n",
    "\n",
    "# Here, we build our model\n",
    "model.build(input_shape=input_shape)\n",
    "\n",
    "# With model.summary() we can pring the model summry and check it.  \n",
    "model.summary()\n",
    "\n",
    "# Now, we compile our model. We are going to pass an optimizer, \n",
    "# how the loss is called\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Then, we can fit our model. Here we pass the training data and the validation data\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff8b554-0261-4e39-b9d6-06b5b3bdf37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we don't want to make a custom model, we can build an sequential easy as that:\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(CustomDenseLayer(64, activation='relu'))\n",
    "model.add(CustomDenseLayer(10, activation='linear'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Then, we can fit our model. Here we pass the training data and the validation data\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))\n",
    "# In historty, we have now the information of our model and what happened duiring the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d35a1b-d652-4a03-a3bc-928466327d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So, we are going to plot the accuracy which was cimputed for the training data\n",
    "# and the validation data for each epoch\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
