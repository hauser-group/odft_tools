{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09957470-25ca-4eb7-98bc-eba872dfb0b9",
   "metadata": {},
   "source": [
    "# TensorBoard\n",
    "\n",
    "With TensorBoard it's possible to visualize and investigate the machine learning model.\n",
    "- Visualize the graph\n",
    "- Track for example metrics like loss and accuracy during hyperparameter training\n",
    "- and many more see https://www.tensorflow.org/tensorboard/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ffa6e5-e8ba-4122-ade9-5c04f9338c65",
   "metadata": {},
   "source": [
    "In this tutorial we will see how a hyperparameter training is done to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abce6fa-87f5-4bec-9c55-dea3ac10afb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from utils.model import (\n",
    "    CustomCNNV1Model\n",
    ")\n",
    "\n",
    "from utils.utils import (\n",
    "    calc_gaussians,\n",
    "    gen_gaussian_kernel_v1_1D,\n",
    "    load_data_cnn,\n",
    "    plot_gaussian_weights,\n",
    "    plot_derivative_energy\n",
    ")\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "# import data\n",
    "data_path = 'data/orbital_free_DFT/'\n",
    "\n",
    "kinetic_train, kinetic_derivativ_train, density_train = load_data_cnn(\n",
    "    path=data_path,\n",
    "    data_name='M=100_training_data.hdf5'\n",
    ")\n",
    "\n",
    "kinetic_test, kinetic_derivativ_test, density_test = load_data_cnn(\n",
    "    path=data_path,\n",
    "    data_name='test_data.hdf5'\n",
    ")\n",
    "\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        density_train.astype(np.float32),\n",
    "        {'T': kinetic_train.astype(np.float32),\n",
    "        'dT_dn': kinetic_derivativ_train.astype(np.float32)}\n",
    "    )\n",
    ").batch(100).repeat(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d838699-d407-4897-bad5-3c0ae8b19f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can define the range/valus and hyperparameters we wabnt to try out.\n",
    "HP_LR = hp.HParam('lr', hp.Discrete([0.01, 0.001])) # learning rate\n",
    "HP_KS = hp.HParam('ks', hp.Discrete([50, 100, 150])) # kernel size\n",
    "HP_FL = hp.HParam('fl', hp.Discrete([4, 8, 16, 32])) # filter length\n",
    "HP_AF = hp.HParam('af', hp.Discrete(['softplus', 'sigmoid'])) # activation function\n",
    "\n",
    "# The metrics we want to track\n",
    "METRIC_LOSS = 'loss'\n",
    "METRIC_T_loss = 'T_loss'\n",
    "METRIC_dT_dn_loss = 'dT_dn_loss'\n",
    "METRIC_T_mae = 'T_mae'\n",
    "METRIC_dT_dn_mae = 'dT_dn_mae'\n",
    "\n",
    "# Define path were results/logging of hyperparameter search will be saved\n",
    "log_dir = 'logs/hyperparam_search/'\n",
    "\n",
    "with tf.summary.create_file_writer(log_dir).as_default():\n",
    "    # Set the hyperparameters and metrics here\n",
    "    hp.hparams_config(\n",
    "    hparams=[HP_LR, HP_KS, HP_FL, HP_AF],\n",
    "    metrics=[\n",
    "        hp.Metric(METRIC_LOSS, display_name='loss'),\n",
    "        hp.Metric(METRIC_T_loss, display_name='T_loss'),\n",
    "        hp.Metric(METRIC_dT_dn_loss, display_name='dT_dn_loss'),\n",
    "        hp.Metric(METRIC_T_mae, display_name='T_mae'),\n",
    "        hp.Metric(METRIC_dT_dn_mae, display_name='dT_dn_mae')\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e8b5de-a3f2-4ba4-9186-7612c8a269ad",
   "metadata": {},
   "source": [
    "Define a method where the model is initialized/build/compiled/fitted.\n",
    "This method is going to be called for each hyperparameter combination\n",
    "and we return the metrics we want to track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf15cf-b1c5-4ef3-9305-d86e64fc449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "    # the hyperparamters for one run are passed as a list\n",
    "\n",
    "    # Now, we initialize/build/compile the model\n",
    "    model = CustomCNNV1Model(\n",
    "        filter_size=hparams[HP_FL],\n",
    "        kernel_size=hparams[HP_KS],\n",
    "        layer_length=3,\n",
    "        dx=0.002,\n",
    "        create_continuous_kernel=gen_gaussian_kernel_v1_1D,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(0.00025),\n",
    "        activation=hparams[HP_AF]\n",
    "    )\n",
    "\n",
    "    model.build(input_shape=(None, 500, 1))\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=hparams[HP_LR], amsgrad=False\n",
    "        ),\n",
    "        loss={'T': 'mse', 'dT_dn': 'mse'},\n",
    "        loss_weights={'T': 0.2, 'dT_dn': 1.0}, # scale the loss in T by 0.2\n",
    "        metrics={'T': ['mae'], 'dT_dn': ['mae']}\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        training_dataset,\n",
    "        epochs=10,\n",
    "        verbose=2, # With 0, there no print of loss. With 1, the print is with loss and a loading bar (batch/epoch), with 2 print with loss \n",
    "        validation_data=(\n",
    "            density_test, {'T': kinetic_test, 'dT_dn': kinetic_derivativ_test}\n",
    "        ),\n",
    "        validation_freq=2\n",
    "    )\n",
    "    \n",
    "    loss = model.history.history['val_loss'][-1]\n",
    "    val_T_loss = model.history.history['val_T_loss'][-1]\n",
    "    val_dT_dn_loss = model.history.history['val_dT_dn_loss'][-1]\n",
    "    val_T_mae = model.history.history['val_T_mae'][-1]\n",
    "    val_dT_dn_mae = model.history.history['val_dT_dn_mae'][-1]\n",
    "    return loss, val_T_loss, val_dT_dn_loss, val_T_mae, val_dT_dn_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba82ddc-8549-4394-878b-ce90bdb14c25",
   "metadata": {},
   "source": [
    "In run we call the train_test_model and logg the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc48d7a-8519-4b77-ab71-c51d4a8a9d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)\n",
    "        loss, val_T_loss, val_dT_dn_loss, val_T_mae, val_dT_dn_mae = train_test_model(hparams)\n",
    "        tf.summary.scalar(METRIC_LOSS, loss, step=1)\n",
    "        tf.summary.scalar(METRIC_T_loss, val_T_loss, step=1)\n",
    "        tf.summary.scalar(METRIC_dT_dn_loss, val_dT_dn_loss, step=1)\n",
    "        tf.summary.scalar(METRIC_T_mae, val_T_mae, step=1)\n",
    "        tf.summary.scalar(METRIC_dT_dn_mae, val_dT_dn_mae, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe441a8-50b0-4423-891c-c84a6f9908a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_num = 0\n",
    "# Don't forget to set a seed\n",
    "seed = 0\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# For all hyperparameters we execute the run method \n",
    "for lr in HP_LR.domain.values:\n",
    "    for fl_size in HP_KS.domain.values:\n",
    "        for kr_length in HP_FL.domain.values:\n",
    "            for activatuion in HP_AF.domain.values:\n",
    "                hparams = {\n",
    "                    HP_LR: lr,\n",
    "                    HP_KS: fl_size,\n",
    "                    HP_FL: kr_length,\n",
    "                    HP_AF: activatuion\n",
    "                }\n",
    "                run_name = \"run-%d\" % session_num\n",
    "                print('--- Starting trial: %s' % run_name)\n",
    "                print({h.name: hparams[h] for h in hparams})\n",
    "                run(log_dir + run_name, hparams)\n",
    "                session_num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
